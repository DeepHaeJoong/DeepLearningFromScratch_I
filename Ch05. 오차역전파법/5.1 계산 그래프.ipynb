{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞 장에서 신경망 학습에 대해서 설명했다. 신경망의 가중치 매개변수의 기울기는 수치 미분을 사용해 구했었다. 수치 미분은 단순하고 구현하기도 쉽지만 계산 시간이 오래 걸린다는게 단점이다. 이번 장에서는 가중치 매개변수의 기울기를 효율적으로 계산하는 '오차역전파법'을 배워보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오차역전파를 이해하는 두 가지 방법\n",
    "- 수식을 이용\n",
    "- **계산 그래프 이용**\n",
    "\n",
    "\n",
    "출처: https://excelsior-cjh.tistory.com/171 [EXCELSIOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 계산 그래프\n",
    "\n",
    "**계산 그래프(computational graph)**는 계산 과정을 그래프로 나타낸 것이며, 노드(node)와 엣지(edge)로 표현된다. 노드는 연산을 정의하며, 엣지는 데이터가 흘러가는 방향을 나타낸다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 계산 그래프 방법\n",
    "\n",
    "다음의 예를 계산 그래프 방법으로 풀어보도록 하자.\n",
    "\n",
    "> 현빈 군은 슈퍼에서 사과를 2개, 귤을 3개 샀습니다. 사과는 1개에 100원, 귤은 1개 150원입니다. 소비세가 10%일 때 지불 금액을 구하라.\n",
    "\n",
    "**[그림 5-3] 계산 그래프로 풀어본 문제 답**\n",
    "<img src=\"https://github.com/DeepHaeJoong/DeepLearningFromScratch_I/blob/master/PNG/Figure%205-2.png?raw=true\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 계산 그래프를 구성한다.\n",
    "2. 그래프에서 계산을 왼쪽에서 오른쪽으로 진행한다. → 순전파(forward propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 국소적 계산\n",
    "\n",
    "계산 그래프의 특징은 '국소적 계산'을 통해 최종 결과를 얻는 것이다. 즉, '자신과 직접 관계된' 범위 내에서만 계산이 이루어 진다. \n",
    "\n",
    "> 슈퍼마켓에서 사과 2개를 포함한 여러 식품을 구입하는 경우. 아래와 같은 그림으로 나타낼 수 있다.\n",
    "\n",
    "**[그림 5-4] 사과 2개를 포함해 여러 식품을 구입하는 예**\n",
    "<img src=\"https://github.com/DeepHaeJoong/DeepLearningFromScratch_I/blob/master/PNG/Figure%205-4.png?raw=true\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서의 핵심은 각 노드에서의 계산은 국소적 계산이라는 점이다. 가령 사과와 그 외의 물품 값을 더하는 계산(2000 + 200 -> 4200)은 4000이라는 숫자가 어떻게 계산되었느냐와는 상관없이, 단지 두 숫자를 더하면 된다는 뜻이다.   \n",
    "\n",
    "#### 즉,각 노드는 자신과 관련한 계산 외에는 아무것도 신경 쓸 게 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 왜 계산 그래프로 푸는가?\n",
    "\n",
    "계산그래프의 장점은 다음과 같다.\n",
    "\n",
    "1. 국소적 계산을 통해 각 노드의 계산에 집중하여 문제를 단순화할 수 있다.\n",
    "\n",
    "2. **역전파를 통해 '미분'을 효율적으로 계산할 수 있다.**\n",
    "\n",
    "> '사과 가격이 오르면 최종 금액에 어떠한 영향을 주는가'에 대해서 **사과 가격에 대한 지불 금액의 미분**을 구해 계산할 수 있다. 사과의 값을 $x$, 지불 금액을 $L$라 했을 때, $\\frac{\\partial L}{\\partial x}$를 구하는 것이다. 이러한 미분 값은 사과 값($x$)가 '아주 조금'올랐을 때 지불 금액($L$)이 얼마나 증가하는지를 나타낸다.\n",
    "\n",
    "**[그림 5-5] 역전파에 의한 미분 값의 전달**\n",
    "\n",
    "<img src=\"https://github.com/DeepHaeJoong/DeepLearningFromScratch_I/blob/master/PNG/Figure%205-5.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 전파는 '국소적 미분'을 전달하고 그 미분 값은 화살표의 아래에 적는다. 이 예에서 역전파는 오른쪽에서 왼쪽으로 `1-> 1.1 -> 2.2`순으로 미분값을 전달한다. 이 결과 '사과 가격에 대한 지불 금액의 미분'값은 2.2라 할 수 있다. 사과가 1원 오르면 최종 금액은 2.2원 오른다는 뜻이다.(정확히는 사과 값이 아주 조금 오르면 최종 금액은 그 아주 작은 값의 2.2배만큼 오른다는 것이다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 연쇄법칙\n",
    "\n",
    "지금까지 해온 계산 그래프의 순전파는 계산 결과를 왼쪽에서 오른쪽으로 전달했었다. 이 순서는 평소 하는 방식이라 어려움이 없었지만, 역전파는 '국소적인 미분'을 순방향과는 반대인 오른쪽에서 왼쪽으로 전달한다.(지금 봐도 당황)..\n",
    "또한, 이 국소적인 미분을 전달하는 원리는 **연쇄법칙**에 따른 것이다. \n",
    "\n",
    "이번 절에서는 연쇄법칙을 설명하고 그것이 계산 그래프 상의 역전파와 같다는 사실을 밝힌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 계산 그래프의 역전파\n",
    "\n",
    "먼저, 역전파 계산 예제로 $y = f(x)$의 역전파를 계산해보자. \n",
    "\n",
    "**[그림 5-6] 계산 그래프의 역전파 : 순방향과는 반대 방향으로 국소적 미분을 곱한다.**\n",
    "\n",
    "<img src=\"https://github.com/DeepHaeJoong/DeepLearningFromScratch_I/blob/master/PNG/Figure%205-6.png?raw=true\">\n",
    "\n",
    "위의 그림에서 처럼 역전파 계산 순서는 신호 $E$에 노드$f(x)$의 국소적 미분 ($\\frac{\\partial y}{\\partial x}$)을 곱한 후 엣지(edge)를 통해 다음 노드로 전달하는 것이다. 여기서 국소적 미분은 순전파 때의 $y = f(x)$에 대한 미분을 구하는 것이고, 이것은 $x$에 대한 $y$의 미분 ($\\frac{\\partial L}{\\partial x}$)을 구한다는 의미이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 연쇄법칙이란?\n",
    "\n",
    "합성 함수 이야기부터 시작해야 합니다. **합성함수**란 여러 함수로 구성된 함수이다.\n",
    "\n",
    "**예제**\n",
    "\n",
    "$$\n",
    "z = t^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "t = x + y\n",
    "$$\n",
    "\n",
    "연쇄법칙은 합성 함수의 미분에 대한 성질이며, 다음과 같이 정의된다.\n",
    "\n",
    "> **합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 : $\\frac{\\partial z}{\\partial x}$ ($x$에 대한 $z$의 미분)은 $\\frac{\\partial z}{\\partial t}$ ($t$에 대한 $z$의 미분)과 $\\frac{\\partial t}{\\partial x}$ ($x$에 대한 $t$의 미분)의 곱으로 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial t} \\frac{\\partial t}{\\partial x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial t} = 2t\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial t}{\\partial x} = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial t} \\frac{\\partial t}{\\partial x} = 2t \\cdot 1 = 2(x+y)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 연쇄법칙과 계산 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 식의 연쇄법칙 계산을 계산 그래프로 나타내보자.\n",
    "\n",
    "**[그림 5-7] 계산 그래프 : 순전파와는 반대 방향으로 국소적 미분을 곱하여 전달한다.**\n",
    "\n",
    "<img src=\"https://github.com/DeepHaeJoong/DeepLearningFromScratch_I/blob/master/PNG/Figure%205-7.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 역전파\n",
    "\n",
    "### 5.3.1 덧셈 노드의 역전파\n",
    "\n",
    "덧셈 노드의 역전파는 입력값을 그대로 흘려보낸다. 이를 보고 gradient distributor라고 하기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z = x + y\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial y} = 1\n",
    "$$\n",
    "\n",
    "**[그림 5-9] 덧셈 노드의 역전파 : 왼쪽이 순전파, 오른쪽이 역전파다. 덧셈 노드의 역전파는 입력 값을 그대로 흘려보낸다.**\n",
    "\n",
    "<img src=\"https://github.com/DeepHaeJoong/DeepLearningFromScratch_I/blob/master/PNG/Figure%205-9.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 곱셈 노드의 역전파\n",
    "\n",
    "곱셈 노드의 역전파는 입력값의 위치를 서로 바꾼 다음 곱해서 흘려보낸다. 이를 보고 gradient switcher라고 부르기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z = xy\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = y\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial y} = x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[그림 5-12] 곱셈 노드의 역전파 : 왼쪽이 순전파.**\n",
    "\n",
    "<img src=\"https://github.com/DeepHaeJoong/DeepLearningFromScratch_I/blob/master/PNG/Figure%205-12.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "곱셈의 역전파는 순방향 입력 신호의 값이 필요합니다. 그래서 곱셈 노드를 구현할 때는 순전파의 입력 신호를 변수에 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 단순한 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 곱셈 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 계층은 **forward()**와 **backward()**라는 공통의 메서드(인터페이스)를 갖도록 구현합니다. forward()는 순전파, backward()는 역전파를 처리한다.\n",
    "\n",
    "**[그림 5-16] 사과 2개 구입**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y # x와 y를 바꾼다.\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순전파를 다음과 같이 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# 게층들\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역전파를 다음과 같이 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dapple : 2.2 \n",
      "dapple_num : 110.00000000000001 \n",
      "dtax :  200\n"
     ]
    }
   ],
   "source": [
    "# 역전파 \n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print('dapple :',dapple, '\\ndapple_num :',dapple_num, '\\ndtax : ', dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 덧셈 계층\n",
    "\n",
    "이어서 덧셈 노드인 덧셈 계층을 구현해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[그림 5-17] 사과 2개와 귤 3개 구입**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n",
      "110, 2.2, 3.3, 165, 650\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n",
    "price = mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print('%d' % price)\n",
    "print(\"%d, %.1f, %.1f, %d, %d\" % (dapple_num, dapple, dorange, dorange_num, dtax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요 계층을 만들어 순전파 메서드인 forward()를 적절한 순서로 호출한다.\n",
    "- 그런 다음 순전파와 반대 순서로 역전파 매서드인 forward()를 호출하면 원하는 미분이 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이처럼 계산 그래프에서 계층을 쉽게 구현할 수 있으며, 이를 사용해 복잡한 미분도 계산할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 활성화 함수 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ReLU\n",
    "- Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 ReLU 계층\n",
    "\n",
    "- **수식**\n",
    "\n",
    "\n",
    "$$\n",
    "y = \\begin{cases} \n",
    "     x \\quad (x > 0) \\\\\n",
    "     0 \\quad (x <= 0) \\\\\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "- **미분**\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial x} = \\begin{cases} \n",
    "     1 \\quad (x > 0) \\\\\n",
    "     0 \\quad (x <= 0) \\\\\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "**[그림 5-18] ReLU 계층의 계산 그래프**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/layers.py\n",
    "import numpy as np\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0) # mask는 True/False로 구성된 넘파이 배열\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " [[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "mask:\n",
      " [[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1., -.5], \n",
    "              [-2., 3.]])\n",
    "print('x:\\n', x)\n",
    "\n",
    "mask = (x <= 0)\n",
    "print('mask:\\n', mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 순전파 때의 입력 값이 0이하면 역전파 때의 값은 0이 돼야 한다. 그래서 역전파 때는 순전파 때 만들어둔 mask를 사용해 mask의 원소가 True인 곳에는 상류에서 전파된 dout을 0으로 설정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Sigmoid 계층\n",
    "\n",
    "- **수식**\n",
    "\n",
    "\n",
    "$$\n",
    "y = \\frac{1}{1+exp(-x)}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**[그림 5-19] Sigmoid 계층의 계산 그래프는 식을 순차적으로 전개함**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1단계\n",
    "\n",
    "**`/`** 노드, 즉 $y = \\frac{1}{x}$ 을 미분하면 다음과 같다.\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial x} = -\\frac{1}{x^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial x} = -y^2\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2단계\n",
    "**`+`** 노드는 상류의 값을 여과 없이 하류로 내보내는 게 전부이다. 계산 그래프에서는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3단계\n",
    "**`exp`** 노드는 $y=exp(x)$의 연산을 수행하며, 그 미분은 다음과 같다.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial x} = exp(x)\n",
    "$$\n",
    "\n",
    "계산 그래프에서는 상류의 값에 순전파 때의 출력(이 예제에서는 $y=exp(-x)$)을 곱해 하류로 전파한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4단계\n",
    "**`x`** 노드는 순전파 때의 값을 '서로 바꿔'곱하게 된다. 이 예제에서는 -1을 곱하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial L}{\\partial y} y^2 exp(-x) = \\frac{\\partial L}{\\partial y}y(1-y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/layers\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        self.out\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Affine/Softmax 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.6 Affine 계층"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
