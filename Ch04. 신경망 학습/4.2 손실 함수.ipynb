{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 신경망 학습에서 사용하는 지표는 **손실 함수**라고 한다. 이 손실 함수는 임의의 함수를 사용할 수도 있지만 일반적으로는 평균 제곱 오차와 교차 엔트로피 오차를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 평균 제곱 오차 (mean square error, MSE)\n",
    "\n",
    "#### 가장 많이 쓰이는 손실 함수\n",
    "\n",
    "- $y_k$ = 신경망의 출력(추정)\n",
    "- $t_k$ = 정답 레이블\n",
    "- k - 데이터 차원 수 (e.g. 0~9인 숫자를 one-hot-encoding 인 경우 k = 10)\n",
    "\n",
    "$$\n",
    "E = \\frac{1}{2}\\sum_k (y_k - t_k)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] # 0 확률, 1 확률, 2 확률, ...\n",
    "t = [0, 0 ,1, 0, 0, 0, 0, 0, 0, 0]  # 정답 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**평균 제곱 오차를 파이썬으로 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답은 '2'\n",
    "t = [0, 0 ,1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "# 예제 1 : '2'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 2 : '7'이 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 1(정답)의 MSE : 0.09750000000000003\n",
    "- 예제 2(오답)의 MSE : 0.5975\n",
    "\n",
    "이 실험의 결과로 정답인 경우의 손실 함수의 출력이 작으며, 평균 제곱 오차를 기준으로 첫 번째 추정 결과가 (오차가 더 작으니) 정답에 더 가까울 것으로 판단할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 교차 엔트로피 오차(cross entropy error, CEE)\n",
    "\n",
    "#### 수식\n",
    "\n",
    "- $\\log$ : 밑이 $e$인 자연로그 ($\\log_e$)\n",
    "- $y_k$ : 신경망의 출력\n",
    "- $t_k$ : 정답 레이블 (정답에 해당하는 인덱스의 원소만 1이고 나머지는 0 [one-hot-encoding))\n",
    "\n",
    "$$\n",
    "E = - \\sum_k t_k \\log y_k\n",
    "$$\n",
    "\n",
    "예를 들어 정답 레이블은 '2'가 정답이라 하고 이때의 신경망 출력이 0.6이면 교차 엔트로피 오차는 $-1 \\times \\log(0.6)$ = 0.51 이다. 또한 같은 조건에서의 신경망 출력이 0.1이라면 $-1 \\times \\log(0.1)$ = 2.30 이다. 즉, 교차 엔트로피 오차는 정답일 때의 출력이 전체 값을 정하게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "plt.plot(data, -np.log(data))\n",
    "plt.scatter(0.6, -np.log(0.6), c = 'r')\n",
    "plt.text(0.65, -np.log(0.6), r'$y_k : 0.6 $')\n",
    "plt.scatter(0.1, -np.log(0.1), c = 'b')\n",
    "plt.text(0.15, -np.log(0.1), r'$y_k : 0.1$')\n",
    "plt.title(\"$y = - \\logx$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답에 해당에 해당하는 출력이 커질수록 0에 다가가다가, 그 출력이 1일 때 0이 된다. 반대로 정답일 때의 출력이 작아질수록 오차는 커진다.\n",
    "\n",
    "교차 엔트로피를 직접 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entoropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y + delta)) # -inf 방지.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답은 '2'\n",
    "t = [0, 0 ,1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 예제 1 : '2'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "cross_entoropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 2 : '7'이 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "cross_entoropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 1(정답)의 CEE : 0.510825457099338\n",
    "- 예제 2(오답)의 CEE : 2.302584092994546\n",
    "\n",
    "이 실험의 결과로 정답인 경우의 손실 함수의 출력이 작으며, 크로스 엔트로피를 기준으로 첫 번째 추정 결과가 (오차가 더 작으니) 정답에 더 가까울 것으로 판단할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 미니배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 위에서 보았던 손실함수 수식은 단일 데이터에만 해당하는 수식이다. 다수의 훈련 데이터를 가지고 손실함수의 합을 구하는 방법을 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수식\n",
    "\n",
    "**평균 손실 함수**\n",
    "\n",
    "- $\\log$ : 밑이 $e$인 자연로그 ($\\log_e$)\n",
    "- $y_{nk}$ : N번째 데이터 입력의 신경망의 출력\n",
    "- $t_{nk}$ : N번째 데이터의 정답 레이블 (정답에 해당하는 인덱스의 원소만 1이고 나머지는 0 [one-hot-encoding))\n",
    "\n",
    "\n",
    "$$\n",
    "E = - \\frac{1}{N} \\sum_{n}\\sum_{k} t_{nk} \\log y_{nk}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append('C:/Users/lhj91/Git/deep-learning-from-scratch-1')\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_train.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터에서 무작위로 10장만 빼내는 python 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size) # 중복 조심..\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13098, 36540, 15481, 37054, 52495, 15824,  5880,  6252, 19804,\n",
       "        7299])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(60000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 (배치용) 교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 하나당 교차 엔트로피 구하는 경우!\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y + 1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 다수(배치)의 교차 엔트로피 구하는 경우, + 데이터 하나당 교차 엔트로피 구하는 경우 (범용적)\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- np.arange(batch_size) : 0 부터 batch_size - 1까지의 배열을 생성\n",
    "- batch_size가 5이면 0~4라는 넘파이 배열을 생성\n",
    "- t : [2, 7, 0, 9, 4]\n",
    "- y[np.arange(batch_size), t] : [y[0,2], y[1,7], y[2,0], y[3,9], y[4,4]] 인 배열을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [0, 2, 4]\n",
    "y = np.array([[0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "             ,[0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "             ,[0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1 , 0.1 , 0.05])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[np.arange(batch_size), t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.30258409, -2.30258409, -2.99573027])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(y[np.arange(batch_size), t] + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5336328198483606"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.sum(np.log(y[np.arange(batch_size), t] + 1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 왜 손실 함수를 설정하는가?\n",
    "\n",
    "왜 굳이 손실 함수를 사용해야 하는걸까? 정확도가 아닌 손실함수를 우회적으로 방법을 택한 이유는 무엇일까?\n",
    "\n",
    "이 의문은 신경망 학습에서의 '미분'의 역할에 주목하면 해결됩니다. 자세한 것은 다음 절에 설명한다. 신경망 학습에서는 최적의 매개변수(가중치와 편향)를 탐색할 때 손실 함수의 값을 가능한 작게 하는 매개변수 값을 찾는 것이다. 이때 매개변수의 미분(정확히는 기울기)을 계산하고, 그 미분값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복한다.\n",
    "\n",
    "단적으로 정확도를 지표로 삼는 경우 미분하면 대부분의 장소에서 0이 되어 매개변수를 갱신할 수 없다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
